{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pranj\\AppData\\Local\\Temp\\ipykernel_24428\\1498862010.py:27: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  lab = mode(labels)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for fold 1 & K = 1  :  0.0899685110211426\n",
      "Accuracy for fold 2 & K = 1  :  0.36527215474583896\n",
      "Accuracy for fold 3 & K = 1  :  0.10751237067026541\n",
      "\n",
      "Mean accuracy for K = 1  :  0.18758434547908232\n",
      "Standard deviation for K = 1  :  0.1258482284986205 \n",
      "\n",
      "Accuracy for fold 1 & K = 2  :  0.09491677912730544\n",
      "Accuracy for fold 2 & K = 2  :  0.36482231219073324\n",
      "Accuracy for fold 3 & K = 2  :  0.09626630679262259\n",
      "\n",
      "Mean accuracy for K = 2  :  0.18533513270355376\n",
      "Standard deviation for K = 2  :  0.12691779756053942 \n",
      "\n",
      "Accuracy for fold 1 & K = 3  :  0.09086819613135402\n",
      "Accuracy for fold 2 & K = 3  :  0.3634727845254161\n",
      "Accuracy for fold 3 & K = 3  :  0.09896536212325686\n",
      "\n",
      "Mean accuracy for K = 3  :  0.18443544759334232\n",
      "Standard deviation for K = 3  :  0.126641665171385 \n",
      "\n",
      "Accuracy for fold 1 & K = 4  :  0.09176788124156546\n",
      "Accuracy for fold 2 & K = 4  :  0.3661718398560504\n",
      "Accuracy for fold 3 & K = 4  :  0.09626630679262259\n",
      "\n",
      "Mean accuracy for K = 4  :  0.18473534263007949\n",
      "Standard deviation for K = 4  :  0.12830812094935617 \n",
      "\n",
      "Accuracy for fold 1 & K = 5  :  0.0899685110211426\n",
      "Accuracy for fold 2 & K = 5  :  0.3661718398560504\n",
      "Accuracy for fold 3 & K = 5  :  0.09716599190283401\n",
      "\n",
      "Mean accuracy for K = 5  :  0.18443544759334232\n",
      "Standard deviation for K = 5  :  0.1285406242847224 \n",
      "\n",
      "Accuracy for fold 1 & K = 6  :  0.09221772379667116\n",
      "Accuracy for fold 2 & K = 6  :  0.36077372919478184\n",
      "Accuracy for fold 3 & K = 6  :  0.09671614934772829\n",
      "\n",
      "Mean accuracy for K = 6  :  0.18323586744639375\n",
      "Standard deviation for K = 6  :  0.12555165795733092 \n",
      "\n",
      "Accuracy for fold 1 & K = 7  :  0.09131803868645974\n",
      "Accuracy for fold 2 & K = 7  :  0.36257309941520466\n",
      "Accuracy for fold 3 & K = 7  :  0.09716599190283401\n",
      "\n",
      "Mean accuracy for K = 7  :  0.18368571000149947\n",
      "Standard deviation for K = 7  :  0.1265150141488964 \n",
      "\n",
      "Accuracy for fold 1 & K = 8  :  0.09041835357624832\n",
      "Accuracy for fold 2 & K = 8  :  0.35807467386414754\n",
      "Accuracy for fold 3 & K = 8  :  0.09671614934772829\n",
      "\n",
      "Mean accuracy for K = 8  :  0.18173639226270807\n",
      "Standard deviation for K = 8  :  0.12471649911300495 \n",
      "\n",
      "Accuracy for fold 1 & K = 9  :  0.0899685110211426\n",
      "Accuracy for fold 2 & K = 9  :  0.3549257759784076\n",
      "Accuracy for fold 3 & K = 9  :  0.09716599190283401\n",
      "\n",
      "Mean accuracy for K = 9  :  0.18068675963412806\n",
      "Standard deviation for K = 9  :  0.12324062383599318 \n",
      "\n",
      "Accuracy for fold 1 & K = 10  :  0.0899685110211426\n",
      "Accuracy for fold 2 & K = 10  :  0.3553756185335133\n",
      "Accuracy for fold 3 & K = 10  :  0.09671614934772829\n",
      "\n",
      "Mean accuracy for K = 10  :  0.18068675963412806\n",
      "Standard deviation for K = 10  :  0.12355438943618742 \n",
      "\n",
      "Accuracy for fold 1 & K = 11  :  0.08816914080071975\n",
      "Accuracy for fold 2 & K = 11  :  0.3535762483130904\n",
      "Accuracy for fold 3 & K = 11  :  0.09626630679262259\n",
      "\n",
      "Mean accuracy for K = 11  :  0.1793372319688109\n",
      "Standard deviation for K = 11  :  0.12324992802362113 \n",
      "\n",
      "Accuracy for fold 1 & K = 12  :  0.08951866846603689\n",
      "Accuracy for fold 2 & K = 12  :  0.3531264057579847\n",
      "Accuracy for fold 3 & K = 12  :  0.09536662168241115\n",
      "\n",
      "Mean accuracy for K = 12  :  0.1793372319688109\n",
      "Standard deviation for K = 12  :  0.12291069205985286 \n",
      "\n",
      "Accuracy for fold 1 & K = 13  :  0.08906882591093117\n",
      "Accuracy for fold 2 & K = 13  :  0.35177687809266756\n",
      "Accuracy for fold 3 & K = 13  :  0.09581646423751687\n",
      "\n",
      "Mean accuracy for K = 13  :  0.1788873894137052\n",
      "Standard deviation for K = 13  :  0.12228236211735904 \n",
      "\n",
      "Accuracy for fold 1 & K = 14  :  0.09041835357624832\n",
      "Accuracy for fold 2 & K = 14  :  0.35132703553756184\n",
      "Accuracy for fold 3 & K = 14  :  0.09536662168241115\n",
      "\n",
      "Mean accuracy for K = 14  :  0.17903733693207377\n",
      "Standard deviation for K = 14  :  0.12184396175297336 \n",
      "\n",
      "Accuracy for fold 1 & K = 15  :  0.08951866846603689\n",
      "Accuracy for fold 2 & K = 15  :  0.349527665317139\n",
      "Accuracy for fold 3 & K = 15  :  0.09581646423751687\n",
      "\n",
      "Mean accuracy for K = 15  :  0.17828759934023095\n",
      "Standard deviation for K = 15  :  0.12111230519570584 \n",
      "\n",
      "Accuracy for fold 1 & K = 16  :  0.08906882591093117\n",
      "Accuracy for fold 2 & K = 16  :  0.3490778227620333\n",
      "Accuracy for fold 3 & K = 16  :  0.09581646423751687\n",
      "\n",
      "Mean accuracy for K = 16  :  0.17798770430349378\n",
      "Standard deviation for K = 16  :  0.12101034151775188 \n",
      "\n",
      "Accuracy for fold 1 & K = 17  :  0.08951866846603689\n",
      "Accuracy for fold 2 & K = 17  :  0.3459289248762933\n",
      "Accuracy for fold 3 & K = 17  :  0.09536662168241115\n",
      "\n",
      "Mean accuracy for K = 17  :  0.1769380716749138\n",
      "Standard deviation for K = 17  :  0.11951842532570135 \n",
      "\n",
      "Accuracy for fold 1 & K = 18  :  0.08951866846603689\n",
      "Accuracy for fold 2 & K = 18  :  0.3481781376518219\n",
      "Accuracy for fold 3 & K = 18  :  0.09536662168241115\n",
      "\n",
      "Mean accuracy for K = 18  :  0.17768780926675665\n",
      "Standard deviation for K = 18  :  0.12057850470085388 \n",
      "\n",
      "Accuracy for fold 1 & K = 19  :  0.0899685110211426\n",
      "Accuracy for fold 2 & K = 19  :  0.34727845254161044\n",
      "Accuracy for fold 3 & K = 19  :  0.09536662168241115\n",
      "\n",
      "Mean accuracy for K = 19  :  0.17753786174838806\n",
      "Standard deviation for K = 19  :  0.12004495275188083 \n",
      "\n",
      "Accuracy for fold 1 & K = 20  :  0.08861898335582546\n",
      "Accuracy for fold 2 & K = 20  :  0.3459289248762933\n",
      "Accuracy for fold 3 & K = 20  :  0.09536662168241115\n",
      "\n",
      "Mean accuracy for K = 20  :  0.17663817663817663\n",
      "Standard deviation for K = 20  :  0.11973832785150751 \n",
      "\n",
      "Best K =  1\n",
      "Accuracy when K =  1  is  0.9210921092109211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pranj\\AppData\\Local\\Temp\\ipykernel_24428\\1498862010.py:102: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  lab = mode(labels)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy when p =  [1, 2, 3, 4]  is  0.9162916291629163\n",
      "Accuracy when p =  [1, 2, 3, 4]  is  0.9210921092109211\n",
      "Accuracy when p =  [1, 2, 3, 4]  is  0.9195919591959196\n",
      "Accuracy when p =  [1, 2, 3, 4]  is  0.9243924392439244\n",
      "Best p is  4\n"
     ]
    }
   ],
   "source": [
    "from decimal import Decimal\n",
    "import math\n",
    "from random import random\n",
    "import sklearn\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from scipy.stats import mode\n",
    "from numpy.random import randint\n",
    "\n",
    "def eucledianDistance(point1,point2):\n",
    "    dist = np.sqrt(np.sum((point1-point2)**2))\n",
    "    return dist\n",
    "\n",
    "def predictor(x_train, y , x_input, k):\n",
    "    predicted_data = []\n",
    "    for item in x_input: \n",
    "        point_distance = []\n",
    "        l = len(x_train)\n",
    "        for j in range(l): \n",
    "            distances = eucledianDistance(np.array(x_train[j,:]) , item) \n",
    "            point_distance.append(distances) \n",
    "        point_distance = np.array(point_distance) \n",
    "        dist = np.argsort(point_distance)[:k] \n",
    "        labels = y[dist]\n",
    "        lab = mode(labels) \n",
    "        lab = lab.mode[0]\n",
    "        predicted_data.append(lab)\n",
    " \n",
    "    return predicted_data\n",
    "\n",
    "def accuracyScore(y_predict,y_test):\n",
    "    l = len(y_predict)\n",
    "    score = 0\n",
    "    for i in range(0,l):\n",
    "        if y_predict[i] == y_test[i]:\n",
    "            score=score+1\n",
    "    return score/l\n",
    "\n",
    "\n",
    "def k_fold_3(x, y,K):\n",
    "    data_len = len(x)\n",
    "    fold_size = data_len // 3\n",
    "    accuracylst = []\n",
    "    for j in range(3):\n",
    "        x_train_data = np.concatenate((x[:j*fold_size],x[(j+1)*fold_size:]),axis=0)\n",
    "        y_train_data = np.concatenate((y[:j*fold_size],y[(j+1)*fold_size:]),axis=0)\n",
    "        x_test_data = x[j*fold_size:(j+1)*fold_size]\n",
    "        y_test_data = y[j*fold_size:(j+1)*fold_size]\n",
    "        y_predicted = predictor(x_train_data,y_train_data,x_test_data , K)\n",
    "        accuracy = accuracyScore(y_predicted,y_test_data)\n",
    "        accuracylst.append(accuracy)\n",
    "        print(\"Accuracy for fold\",j+1,\"& K =\",K,\" : \",accuracy)\n",
    "    print(\"\\nMean accuracy for K =\",K,\" : \",np.mean(accuracylst))\n",
    "    print(\"Standard deviation for K =\",K,\" : \",np.std(accuracylst),\"\\n\")\n",
    "    return np.mean(accuracylst)\n",
    "\n",
    "train_data = pd.read_csv(\"pp_tra.dat\", sep=\" \", header=None)\n",
    "test_data = pd.read_csv(\"pp_tes.dat\", sep=\" \", header=None)\n",
    "\n",
    "X_train = train_data.iloc[:,:-1].to_numpy()\n",
    "Y_train = train_data.iloc[:,-1].to_numpy()\n",
    "\n",
    "X_test = test_data.iloc[:,:-1].to_numpy()\n",
    "Y_test = test_data.iloc[:,-1].to_numpy()\n",
    "\n",
    "K = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]\n",
    "accuracylst = []\n",
    "for i in K:\n",
    "    accuracy = k_fold_3(X_train,Y_train,i)\n",
    "    accuracylst.append(accuracy)\n",
    "\n",
    "Best_K = K[accuracylst.index(max(accuracylst))]\n",
    "\n",
    "print(\"Best K = \",Best_K)\n",
    "\n",
    "y_predicted = predictor(X_train,Y_train,X_test , Best_K)\n",
    "accuracy = accuracyScore(y_predicted,Y_test)\n",
    "print(\"Accuracy when K = \",Best_K, \" is \",accuracy)\n",
    "\n",
    "def p_root(value, root):\n",
    "     \n",
    "    root_value = 1 / float(root)\n",
    "    return round (value **root_value, 3)\n",
    " \n",
    "def minkowski_distance(x, y, p):\n",
    "    return (p_root(sum(pow(abs(a-b), p)\n",
    "            for a, b in zip(x, y)), p))\n",
    "\n",
    "def predictor_minkowski(x_train, y , x_input, k , p):\n",
    "    predicted_data = []\n",
    "    for item in x_input: \n",
    "        point_distance = []\n",
    "        l = len(x_train)\n",
    "        for j in range(l): \n",
    "            distances = minkowski_distance(np.array(x_train[j,:]) , item, p)\n",
    "            point_distance.append(distances) \n",
    "        point_distance = np.array(point_distance) \n",
    "        dist = np.argsort(point_distance)[:k] \n",
    "        labels = y[dist]\n",
    "        lab = mode(labels) \n",
    "        lab = lab.mode[0]\n",
    "        predicted_data.append(lab)\n",
    " \n",
    "    return predicted_data\n",
    "\n",
    "\n",
    "p = [1,2,3,4]\n",
    "accuracylst1 = []\n",
    "for i in p:\n",
    "    y_predicted = predictor_minkowski(X_train,Y_train,X_test , Best_K , i)\n",
    "    accuracy = accuracyScore(y_predicted,Y_test)\n",
    "    accuracylst1.append(accuracy)\n",
    "    print(\"Accuracy when p = \",p[i], \" is \",accuracy)\n",
    "\n",
    "print(\"Best p is \",accuracylst1.index(max(accuracylst1))+1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9193c1a9913195caabc2c874ca2de0cb16dd52b286f913a03acced765754a1e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
